---
title: "Interpretation of Classification Models"
output: rmarkdown::html_vignette
description: >
  Demonstrates how to use the midr package to interpret classification models.
vignette: >
  %\VignetteIndexEntry{Interpretation of Classification Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

pkgs <- c("mlbench", "gridExtra", "ggplot2", "Metrics", "DALEX",
          "glmnet", "ranger", "e1071", "nnet", "rpart", "gam", "xgboost")
for (pkg in pkgs) {
  if (!(pkg %in% installed.packages())) {
    install.packages(pkg)
  }
}
```

This article presents some examples of the interpretation of classification models using `midr`. 

```{r setup, message = FALSE}
# load required packages
library(midr)
library(ggplot2)
library(gridExtra)
library(Metrics)
theme_set(theme_midr())
```

## Classification Task

We use the titanic dataset, which is available on the website https://www.encyclopedia-titanica.org/ and is included in the `DALEX` package. The dataset has 9 variables for 2207 people, of which 1317 were passengers and 890 were crew members. We fit some classification models that predict who survived the tragedy and who did not, and then we interpret the fitted models.

```{r titanic}
# benchmark classification task
library(DALEX)
set.seed(42)
test_rows <- sample(nrow(titanic), 500L)
train <- titanic[-test_rows, -5]
str(train)
test  <- titanic[ test_rows, -5]
str(test[, -9])
```

For each model type, we fit a classification model using the training dataset of 1707 people and an interpretative MID surrogate of the target model using the same dataset. We then evaluate the predictive accuracy of the target model by AUC and the representation accuracy of the surrogate model by the Spearman's rank correlation coefficient between two predicted probabilities.

In the following examples, we use two specialized link functions for classification tasks: `translogit` (transformed-logit) and `transprobit` (transformed-probit). These two link functions are transformed so that $g(0.5) = 0.5$ and $g'(0.5) = 1$. With these link functions, the effects on the linear predictor can be approximately interpreted as the upper bound of the effects on the predicted probabilities.

```{r, echo = FALSE, fig.height = 3, fig.width = 6}
par.midr(mfrow = c(1, 2))
link <- midr:::get.link("translogit")
curve(link$linkfun(x), 0, 1)
title("transformed-logit")
abline(0, 1, lty = 3)
link <- midr:::get.link("transprobit")
curve(link$linkfun(x), 0, 1)
title("transformed-probit")
abline(0, 1, lty = 3)
```

```{r utils}
# define utility functions for the following chunks
effect_plots <- function(object) {
  plots <- mid.plots(mid, terms = terms(mid)[1:6])
  for (i in 1:6) {
    plots[[i]] <- plots[[i]] + ggtitle("main effect")
    if (any(i == c(1, 3, 4)))
      plots[[i]] <- plots[[i]] + coord_flip()
  }
  plots
}

interaction_plot <- function(
    object, term = NULL, theme = "shap") {
  if (is.null(term))
    term <- mid.terms(mid.importance(object), main.effect = FALSE)[1L]
  ggmid(object, term, type = "data", data = na.omit(titanic), 
        theme = theme, main.effects = TRUE) +
    theme(legend.position = "right") +
    ggtitle("interaction effect plot")
}

ice_plot <- function(object, variable = "age") {
  ggmid(mid.conditional(object, variable,
                        data = na.omit(titanic)[1:200, ]),
        var.color = gender, theme = "shap_r") +
    theme(legend.position = "right") +
    ggtitle("conditional expectation")
}

importance_plot <- function(object) {
  ggmid(mid.importance(object), "heatmap", theme = "grayscale") +
    theme(legend.position = "right") +
    ggtitle("feature importance")
}

evaluation_plot <- function(model, mid, ...) {
  pred <- get.yhat(model, test, ...)
  pred_mid <- get.yhat(mid, test)
  actual <- as.numeric(test$survived == "yes")
  auc_vs_test <- auc(actual, pred)
  cor_vs_mid <-  cor(pred, pred_mid, method = "spearman",
                     use = "pairwise.complete.obs")
  ggplot() + scale_color_theme("Accent") +
    geom_point(aes(x = pred, y = pred_mid), col = "#4378bf",
               data = na.omit(data.frame(pred, pred_mid))) +
    geom_abline(slope = 1, intercept = 0, col = "black", lty = 2) +
    theme(legend.position = "right") + xlim(0, 1) +
    labs(x = "model-prediction", y = "mid-prediction") +
    annotate("text", family = "serif", size = 3, x = 0.2, y = 0.8,
      label = sprintf("vs test (AUC)       : %.3f\nvs mid (Spearman): %.3f",
                      auc_vs_test, cor_vs_mid)
    ) + ggtitle("representation accuracy")
}
```

## Additive Models

### Logistic Regression

```{r stats_glm}
model <- glm(survived == "yes" ~ ., family = "binomial", data = train)
mid <- interpret(survived ~ .^2, train, model, link = "translogit")
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             evaluation_plot(model, mid, target = "yes"))
```

## Neural Network

### Single Hidden Layer Network

```{r nnet_nnet}
library(nnet)
set.seed(42)
model <- nnet(survived ~ ., train, size = 5, maxit = 1e3, trace = FALSE)
mid <- interpret(survived ~ .^2, train, model, link = "transprobit",
                 lambda = .01)
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             evaluation_plot(model, mid))
```

## Support Vector Machine

### RBF Kernel SVM

```{r e1071_svm}
library(e1071)
model <- svm(survived ~ ., train, kernel = "radial", probability = TRUE)
mid <- interpret(survived ~ .^2, train, model, link = "transprobit",
                 pred.args = list(target = "yes"))
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             evaluation_plot(model, mid, target = "yes"))
```

## Tree Based Models

### Random Forest

```{r ranger_ranger}
library(ranger)
set.seed(42)
model <- ranger(survived ~ ., na.omit(train), probability = TRUE)
mid <- interpret(survived ~ .^2, train, model,
                 link = "transprobit", lambda = .01)
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             evaluation_plot(model, mid, target = "yes"))
```

### Decision Tree

```{r rpart_rpart}
library(rpart)
model <- rpart(survived ~ ., train)
# create encoding frames for CART
frm <- cbind(model$frame, labels(model, collapse = FALSE))
print(t(frm[frm$var != "<leaf>", c("var", "ltemp")]))
fun <- function(x) if (is.numeric(x)) range(x, na.rm = TRUE) else levels(x)
frames <- lapply(train, fun)
frames$age <- c(frames$age, 9.5, 54.5, 36.5)
frames$fare <- c(frames$fare, 26.63, 24.56)
frames$sibsp <- c(frames$fare, 2.5)
mid <- interpret(survived ~ .^2, train, model, link = "transprobit",
                 singular.ok = TRUE, type = 0, frames = frames)
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             evaluation_plot(model, mid, target = "yes"))
```

## Other Models

### Predictive MID

To fit a MID model for the Titanic classification task, we can use "one-sided" link functions: `identity-gaussian` or `identity-logistic`. These link functions map $0$ to $0$ and $1$ to $1$, while the inverse link functions map any real number to the value in the unit interval $(0, 1)$.

```{r, echo = FALSE, fig.height = 3, fig.width = 6}
par.midr(mfrow = c(1, 2))
link <- midr:::get.link("identity-gaussian")
curve(link$linkfun(x), 0, 1)
title("link: identity")
abline(0, 1, lty = 3)
curve(link$linkinv(x), -.8, 1.8)
title("inverse link: gaussian QDF")
abline(0, 1, lty = 3)
```

```{r midr_interpret}
mid <- interpret(survived ~ .^2, train,
                 link = "identity-gaussian", lambda = .1)
print(mid)
grid.arrange(grobs = effect_plots(mid), nrow = 2L)
grid.arrange(nrow = 2L,
             importance_plot(mid),
             interaction_plot(mid),
             ice_plot(mid),
             interaction_plot(mid, "age:class"))
```

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret.R
\name{interpret}
\alias{interpret}
\alias{interpret.default}
\alias{interpret.formula}
\title{Fit MID Models}
\usage{
interpret(object, ...)

\method{interpret}{default}(
  object,
  x,
  y = NULL,
  weights = NULL,
  pred.fun = get.yhat,
  link = NULL,
  k = c(NA, NA),
  type = c(1L, 1L),
  frames = list(),
  interaction = FALSE,
  terms = NULL,
  singular.ok = FALSE,
  mode = 1L,
  method = NULL,
  lambda = 0,
  kappa = 1e+06,
  na.action = getOption("na.action"),
  encoding.digits = 3L,
  use.catchall = FALSE,
  catchall = "(others)",
  max.ncol = 3000L,
  nil = 1e-07,
  tol = 1e-07,
  ...
)

\method{interpret}{formula}(
  formula,
  data = NULL,
  model = NULL,
  pred.fun = get.yhat,
  weights = NULL,
  subset = NULL,
  na.action = getOption("na.action"),
  mode = 1L,
  drop.unused.levels = FALSE,
  ...
)
}
\arguments{
\item{object}{a fitted model object to be interpreted.}

\item{...}{hidden controlling parameters and special aliases such as \code{ok} for \code{singular.ok} and \code{} for \code{interactions}.}

\item{x}{a matrix or a data frame of predictor variables to be used to interpret the model predictions. The response variable should not be included.}

\item{y}{an optional numeric vector of the model predictions or the response variable.}

\item{weights}{optional. A numeric vector of sample weights for each observation in \code{x}.}

\item{pred.fun}{a function to obtain predictions from a fitted model, where the first argument is for the fitted model and the second argument is for new data. The default is \code{get.yhat()}.}

\item{link}{a character. One of "logit", "probit", "cauchit", "cloglog", "identity", "log", "sqrt", "1/mu^2", and "inverse".}

\item{k}{an integer or a numeric vector of length two, specifying the maximum number of sample points for each variable. If an integer is passed, \code{k} is used for main effects and \code{sqrt(k)} is used for interactions. If not positive, all unique values are used as sample points.}

\item{type}{an integer or a numeric vector of length two, specifying the type of encoding. The effects of quantitative variables are modeled as piecewise linear functions if \code{type} is \code{1}, and as step functions if \code{type} is \code{0}.}

\item{frames}{a named list of encoding frames.}

\item{interaction}{logical. If \code{TRUE} and if \code{terms} and \code{formula} are not supplied, all interactions for each pair of variables are calculated.}

\item{terms}{a character vector of term labels, specifying the set of component functions to be modeled. If not passed, \code{terms} include all main effects and all interactions if \code{interaction} is \code{TRUE}.}

\item{singular.ok}{logical. If \code{FALSE}, a singular fit is an error.}

\item{mode}{an integer specifying the method of calculation. If \code{mode} is \code{1}, the centralization constraints are treated as penalties for the least squares problem. If \code{mode} is \code{2}, the constraints are used to reduce the number of free parameters.}

\item{method}{an integer or a vector of length two, specifying the methods to be used to solve the least squares problem. A non-negative value will be passed to \code{RcppEigen::fastLmPure()}. If negative, \code{stats::lm.fit()} is used.}

\item{lambda}{a numeric parameter that controls the strength of the smoothing penalty.}

\item{kappa}{a numeric parameter that controls the strength of the penalty for the centralization. Used only when \code{mode} is \code{1}.}

\item{na.action}{a function or a character specifying the method of handling \code{NA}s. The default is na.omit.}

\item{encoding.digits}{an integer specifying the rounding digits for encoding numeric variables. Used only when \code{type} is \code{1}.}

\item{use.catchall}{logical. If \code{TRUE}, less frequent levels of factor variables are dropped and replaced by the catchall level.}

\item{catchall}{a character specifying the catchall level.}

\item{max.ncol}{an integer specifying the maximum number of columns of the design matrix.}

\item{nil}{a threshold for the intercept and coefficients to be treated as zero. The default is \code{1e-7}.}

\item{tol}{a tolerance for the singular value decomposition. The default is \code{1e-7}.}

\item{formula}{a symbolic description of the decomposition model to be fit.}

\item{data}{a data frame containing the variables in the formula. If not found in data, the variables are taken from environment(formula).}

\item{model}{a model object to be interpreted.}

\item{subset}{an index vector specifying the rows to be used in the training sample.}

\item{drop.unused.levels}{logical. If TRUE, unused levels of factors will be dropped.}
}
\value{
\code{interpret()} returns a 'mid' object with the following components:
\item{weights}{a numeric vector of the sample weights.}
\item{call}{the matched call.}
\item{terms}{a character vector of the terms.}
\item{link}{a 'link-glm' object specifying the link function.}
\item{intercept}{the fitted intercept.}
\item{encoders}{a list of encoders.}
\item{main.effects}{a list of data frames representing the fitted main effects.}
\item{interacions}{a list of data frames representing the fitted interactions.}
\item{uninterpreted.rate}{the ratio of the interpretation loss to the original variance of model predictions (yhat).}
\item{fitted.matrix}{a matrix showing the breakdown of the predictions into the effects of the component functions.}
\item{linear.predictors}{a numeric vector of the linear predictors.}
\item{fitted.values}{a numeric vector of the fitted values.}
\item{residuals}{a numeric vector of the working residuals.}
\item{na.action}{information about the special handlings of \code{NA}s.}
}
\description{
\code{interpret()} is used to fit a MID model specifically as an interpretable surrogate for black-box ML models.
A fitted MID model consists of a set of component functions, each with up to two variables.
}
\details{
The prediction function of a fitted MID model \eqn{\hat{f}(x)} has the following structure:
\deqn{\hat{f}(x) = f_{\phi} + \Sigma_{j\ \in D}\ f_{j}(x_j) + \Sigma_{j,k\ \in D}\ f_{j,k}(x_j, x_k)}
where, \eqn{f_\phi} is the intercept, \eqn{f_{j}(x_j)} is the main effect of the variable \eqn{j}, and \eqn{f_{j,k}(x_j, x_k)} is the second-order interaction between the two variables \eqn{j} and \eqn{k}.
The effects of quantitative variables are modeled as piecewise functions of degree 1 (piecewise linear function) or 0 (step function).

The MID values for each sample point are determined using the constrained least squares method.
The loss function is \eqn{\Sigma (f(x)-\hat{f}(x))^2} if a fitted model \eqn{f(x)} is passed, and \eqn{\Sigma (y-\hat{f}(x))^2} if not.
The constraint functions are \eqn{E[f_j(X_j)] = 0} for each variable \eqn{j} and \eqn{E[f_{j,k}(X_j, X_k)]=E[f_{j,k}(X_j, X_k)|X_j]=E[f_{j,k}(X_j, X_k)|X_k]=0} for each pair of variables \eqn{(j,k)}.
}
\examples{
data(cars, package = "datasets")
model <- lm(dist ~ I(speed^2) + speed, cars)
mid <- interpret(dist ~ speed, cars, model)
plot(mid, "speed", add.intercept = TRUE) +
  points(cars)
summary(mid)

data(Nile, package = "datasets")
mid <- interpret(x = 1L:100L, y = Nile, k = 100L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)
# reduce number of knots by k parameter
mid <- interpret(x = 1L:100L, y = Nile, k = 10L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)
# pseudo-smoothing by lambda parameter
mid <- interpret(x = 1L:100L, y = Nile, k = 100L, lambda = 100L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)

data(airquality, package = "datasets")
airquality$Month <- factor(airquality$Month)
model <- glm(Ozone ~ .^2, Gamma(log), airquality)
mid <- interpret(Ozone ~ .^2, na.omit(airquality), model, lambda = .1)
summary(mid)
plot(mid, "Wind")
plot(mid, "Temp")
plot(mid, "Wind:Month", include.main.effects = TRUE)
}

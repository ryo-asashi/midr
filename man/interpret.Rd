% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret.R
\name{interpret}
\alias{interpret}
\alias{interpret.default}
\alias{interpret.formula}
\title{Create an Interpretable Surrogate of Black-Box ML Models}
\usage{
interpret(object, ...)

\method{interpret}{default}(
  object,
  x,
  y = NULL,
  weights = NULL,
  pred.fun = get.yhat,
  link = NULL,
  k = c(NA, NA),
  type = c(1L, 1L),
  frames = list(),
  interaction = FALSE,
  terms = NULL,
  singular.ok = FALSE,
  mode = 1L,
  method = NULL,
  lambda = 0,
  kappa = 1e+06,
  na.action = getOption("na.action"),
  encoding.digits = 3L,
  use.catchall = FALSE,
  catchall = "(others)",
  max.ncol = 3000L,
  nil = 1e-07,
  tol = 1e-07,
  ...
)

\method{interpret}{formula}(
  formula,
  data = NULL,
  model = NULL,
  pred.fun = get.yhat,
  weights = NULL,
  subset = NULL,
  na.action = getOption("na.action"),
  mode = 1L,
  drop.unused.levels = FALSE,
  ...
)
}
\arguments{
\item{object}{a fitted model object to be interpreted.}

\item{...}{special aliases for some arguments, including 'ie' for 'interaction' and 'ok' for 'singular.ok'.}

\item{x}{a matrix or a data frame of predictor variables to be used to interpret the model prediction. The response variable should not be included.}

\item{y}{an optional numeric vector representing of the model prediction or the response variable.}

\item{weights}{optional. a numeric vector indicating weights for each row in the data.}

\item{pred.fun}{a function that takes two arguments, 'X.model' and 'newdata' to be used to make a prediction. Default is \code{get.yhat()}, which uses \code{DALEX::yhat()} if the DALEX package is installed.}

\item{link}{name of the link function. One of "logit", "probit", "cauchit", "cloglog", "identity", "log", "sqrt", "1/mu^2", "inverse".}

\item{k}{an integer or a numeric vector of length two for main effects and interactions, specifying the maximum number of sample points for each numeric predictor variable. If an integer is passed, k is used for main effect terms and the square root of k is used for interaction terms. If not positive, all unique values are used as sample points.}

\item{type}{an integer or a vector of length two, specifying the type of piecewise functions to be fit on numeric variables. '0' is for step functions on discretized intervals, and '1' is for piecewise linear functions connecting at representative values.}

\item{frames}{a named list of encoding frames, which specifies bins for quantitative features or levels for qualitative features.}

\item{interaction}{logical. If TRUE, and if \code{terms} and \code{formula} are not supplied, all second order interaction effects for each pair of features in \code{x} are calculated.}

\item{terms}{a character vector of term labels, specifying the set of decomposition terms. If not passed, all main effects (and all second order interactions if \code{interaction} is TRUE) of \code{x} are used.}

\item{singular.ok}{logical. If FALSE, a singular fit is an error.}

\item{mode}{an integer specifying the general method of calculation. When \code{mode} is set to 1, centralization constraints are treated as penalties for the least squares problem. If \code{mode} is 2, the centralization constraints are used to reduce the number of unknown parameters, making the calculation safer and more robust.}

\item{method}{an integer or a vector of length two, specifying the methods to be used to solve the least squares problem. A non-negative value will be passed to RcppEigen::fastLmPure and if a negative value is passed, stats::lm.fit will be used.}

\item{lambda}{a numeric parameter for the penalty of weighted ridge regularization.}

\item{kappa}{a numeric parameter for the penalty of the centralization constraints. Only used if \code{mode} is 1.}

\item{na.action}{a function or a character which indicates what should happen when the data contain missing values (NAs). The default is na.omit.}

\item{encoding.digits}{an integer specifying the rounding digits for encoding numeric variables when \code{type} is 1 (piecewise linear functions).}

\item{use.catchall}{logical. If TRUE, less frequent levels are dropped and replaced with the catchall level.}

\item{catchall}{a character used as the name of "catchall" level for unused levels of each factor variable.}

\item{max.ncol}{an integer which indicates the maximum number of columns of the design matrix.}

\item{nil}{a threshold for the intercept and coefficients to be treated as zero. Default is 1e-7.}

\item{tol}{a tolerance for the singular value decomposition. Default is 1e-7.}

\item{formula}{a symbolic description of the decomposition model to be fit.}

\item{data}{a data frame containing the variables in the formula. If not found in data, the variables are taken from environment(formula).}

\item{model}{a model object to be interpreted.}

\item{subset}{an index vector specifying the rows to be used in the training sample.}

\item{drop.unused.levels}{logical. If TRUE, unused levels of factors will be dropped.}
}
\value{
\code{interpret()} returns an object of class "mid", which is a list containing the following components:
\item{weights}{a numeric vector of the weights.}
\item{call}{the matched call.}
\item{terms}{a character vector of decomposition term names.}
\item{link}{a list of class "mid-link", specifying the link function used.}
\item{intercept}{the fitted zeroth-order effect.}
\item{main.effects}{a list of data frames representing the fitted first-order (main) effects of each variable.}
\item{me.encoders}{a list of encoders for the first-order decomposition.}
\item{interacions}{a list of data frames representing the fitted second-order interactions.}
\item{ie.encoders}{a list of encoders for the second-order decomposition.}
\item{uninterpreted.rate}{the ratio of the interpretation loss to the original variance of model predictions (yhat).}
\item{fitted.matrix}{a matrix containing the breakdown of the fitted values into the functional decomposition terms.}
\item{linear.predictors}{a numeric vector of the linear predictors.}
\item{fitted.values}{a numeric vector of the fitted values.}
\item{residuals}{a numeric vector of the working residuals.}
\item{na.action}{information on the special handlings of NAs.}
}
\description{
Construct a predictive model consisting of a set of functions, each with up to two variables.
}
\examples{
data(cars, package = "datasets")
model <- lm(dist ~ I(speed^2) + speed, cars)
mid <- interpret(dist ~ speed, cars, model)
plot(mid, "speed", add.intercept = TRUE) +
  points(cars)
summary(mid)

data(Nile, package = "datasets")
mid <- interpret(x = 1L:100L, y = Nile, k = 100L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)
# reduce number of knots by k parameter
mid <- interpret(x = 1L:100L, y = Nile, k = 10L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)
# pseudo-smoothing by lambda parameter
mid <- interpret(x = 1L:100L, y = Nile, k = 100L, lambda = 100L)
plot(mid, "x", add.intercept = TRUE, ylim = c(600L, 1300L)) +
  points(x = 1L:100L, y = Nile)

data(airquality, package = "datasets")
airquality$Month <- factor(airquality$Month)
model <- glm(Ozone ~ .^2, Gamma(log), airquality)
mid <- interpret(Ozone ~ .^2, na.omit(airquality), model, lambda = .1)
summary(mid)
plot(mid, "Wind")
plot(mid, "Temp")
plot(mid, "Wind:Month", include.main.effects = TRUE)
}
